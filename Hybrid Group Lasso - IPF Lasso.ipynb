{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parallelisation of Hybrid Group-IPF Lasso\n",
    "\n",
    "# Upload the data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import cvxpy as cp\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# X_train, X_test, Y_train, Y_test = ...\n",
    "# flux_dimensions_index = size of features for the fluxes - 1\n",
    "# gene_dimensions_index = size of features for the genes - 1\n",
    "\n",
    "indices1 = []                        #  indices identifying the groups for the fluxes\n",
    "indices2 = []                        #  indices identifying the groups for the genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import worker_function as wf\n",
    "import multiprocess\n",
    "from itertools import repeat as iterreap\n",
    "\n",
    "number_of_workers = 12               \n",
    "lambd_values = np.logspace(-0.6, 0.7, number_of_workers)                   \n",
    "intercept_values = np.logspace(-1.6, 0.04, number_of_workers)\n",
    "\n",
    "lambdas1 = np.repeat(lambd_values, len(intercept_values)*len(lambd_values))\n",
    "lambdas2 = np.repeat(lambd_values, len(intercept_values))\n",
    "lambdas2 = np.asarray([lambdas2[:] for _ in range(len(lambd_values))]).flatten()\n",
    "intercepts =  np.asarray([intercept_values[:] for _ in range(len(lambd_values)**2)]).flatten()\n",
    "\n",
    "\n",
    "if __name__ ==  '__main__': \n",
    "    start_time = time.time()\n",
    "    print(\"Starting process...\")\n",
    "    with multiprocess.Pool(20) as pool:\n",
    "        results = pool.starmap(wf.optimise, zip(range(len(lambdas1)), lambdas1, # we pass a universal id, not the worker id\n",
    "                                      lambdas2, intercepts, iterreap(X_train), iterreap(Y_train), \n",
    "                                      iterreap(X_test), iterreap(Y_test), iterreap(flux_dimensions_index), \n",
    "                                      iterreap(gene_dimensions_index), iterreap(indices1), iterreap(indices2)))\n",
    "    \n",
    "    print(\"Finished. Total time required (in minutes): \", (time.time() - start_time)/60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(results), len(lambdas1))\n",
    "clean_results = list()\n",
    "for idx, res in enumerate(results):\n",
    "    if idx == 0:\n",
    "        clean_results = [res[0], res[1], res[2], res[3], res[6], res[7], res[8]]\n",
    "    else:\n",
    "        clean_results = np.vstack((clean_results, [res[0], res[1], res[2], res[3], res[6], res[7], res[8]]))\n",
    "    if res[8] <= 0.0058:\n",
    "        print(\"Worker {}, Lambda1: {}, Lambda2: {}, Intercept: {}, Total time: {}, Train error: {}, Test error: {}\".format(\n",
    "            res[0], res[1], res[2], res[3], res[6], res[7], res[8]))\n",
    "        \n",
    "pd.DataFrame(clean_results, columns=[\"Worker\", \"Lambda1\", \"Lambda2\", \"Intercept\", \"Total time\", \"Train error\", \"Test error\"]).to_csv(\"\", encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_anaconda3)",
   "language": "python",
   "name": "conda_anaconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
